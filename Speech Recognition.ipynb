{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d841fff0",
   "metadata": {},
   "source": [
    "## Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b13ca",
   "metadata": {},
   "source": [
    "### 1 - Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b05c1b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data set size =  30\n",
      "test data size = 10\n",
      "language alphabet == ['A', 'o', 'e', 't', 'p', 'g', 'k']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "### GET DATA ###\n",
    "path = '/Users/anosharahim/cs156-pcw-anosharahim/23/'\n",
    "trainA = os.listdir(path + 'trainA')\n",
    "trainB = os.listdir(path + 'trainB')\n",
    "trainC = os.listdir(path + 'trainC')\n",
    "ts = os.listdir(path + 'test')\n",
    "\n",
    "#unique alphabet encodings\n",
    "alphabet = ['A', 'o', 'e', 't', 'p', 'g', 'k']\n",
    "alphabet_dict = {'o': 0, 'p': 1, 't': 2, 'e': 3, 'k': 4, 'g': 5, 'A': 6} #\n",
    "\n",
    "def getfiles(folder,folder_name, pth): \n",
    "    items = []\n",
    "    c=0\n",
    "    for item in folder: \n",
    "        myfile = open(pth+folder_name+'/'+item)\n",
    "        c+=1\n",
    "        \n",
    "        for line in myfile:\n",
    "            items.append(line)   \n",
    "    return items\n",
    "\n",
    "\n",
    "A_tr = getfiles(trainA, 'trainA', path)\n",
    "trainB.pop(18) #remove .DStore file\n",
    "B_tr = getfiles(trainB, 'trainB', path)\n",
    "C_tr = getfiles(trainC, 'trainC', path)\n",
    "print('training data set size = ', len(A_tr))\n",
    "\n",
    "test = getfiles(ts, 'test', path)\n",
    "print('test data size =', len(test))\n",
    "print('language alphabet ==',alphabet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "395972d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions for transition matrix, log probability and language detection ### \n",
    "\n",
    "def T_matrix(sequences, dict_):\n",
    "    '''Returns transition matrix of a list of sequences. \n",
    "    \n",
    "    Input\n",
    "    sequences: list of str\n",
    "    dict_: dictionary of letters as keys and their encoding as values.\n",
    "    \n",
    "    Output \n",
    "    M: list of lists\n",
    "    where M[i][j] is the probability of transitioning from i to j\n",
    "    '''\n",
    "    \n",
    "    #initialize transition matrix with cols = alphabet size\n",
    "    T = [[0]*7 for _ in range(7)] \n",
    "    \n",
    "    for seq in sequences: #for each sequence\n",
    "        seq = list(seq) #create list of chars from string\n",
    "        #get encoding for letters in sequence \n",
    "        e = [dict_[letter] for letter in seq] \n",
    "        \n",
    "        for (i,j) in zip(e,e[1:]): #count the transitions \n",
    "            T[i][j] += 1 #append when state transitions from i to j\n",
    "            \n",
    "    #once counted, convert to probabilities\n",
    "    for row in T:\n",
    "        n = sum(row) #row should sum to 1\n",
    "        if n > 0:\n",
    "            #normalize rows\n",
    "            row[:] = [f/sum(row) for f in row]\n",
    "            \n",
    "    return T #transition matrix\n",
    "\n",
    "\n",
    "def log_probability(seq, t_matrix, letters = alphabet):\n",
    "    '''Returns log probability that a sequence is from a given language.\n",
    "    '''\n",
    "    log_prob = 0 #initialize log probability to zero  \n",
    "    \n",
    "    for i in range(len(seq)-1): \n",
    "        #for each sequence, get current and next letter\n",
    "        curr_ = letters.index(seq[i])\n",
    "        next_ = letters.index(seq[i+1])\n",
    "        #print(type(curr_),type(next_))\n",
    "        #find probability of going from curr to next in the transition matrix\n",
    "        prob = t_matrix[curr_, next_]\n",
    "        \n",
    "        #fix if probability is greater than 0\n",
    "        if prob > 0:\n",
    "            log_prob += np.log(prob)\n",
    "    return log_prob \n",
    "\n",
    "\n",
    "def language_detector(seq, t_matrices, letters = alphabet) -> str:\n",
    "    '''Returns the most probable language a sequence (str) is from.\n",
    "    Input \n",
    "    seq: str for which language is to be detected \n",
    "    t_matrices: list of lists, transition matrix of each language\n",
    "    letters: list of strs of alphabet in language \n",
    "    \n",
    "    Output \n",
    "    lang_p: most probable language of sequence\n",
    "    '''\n",
    "    lang_p = [] #store language probabilities here\n",
    "    for name, t_matrix in t_matrices: #for each transition matrix\n",
    "        lang_p.append(log_probability(seq, t_matrix, letters)) #get log probability \n",
    "    \n",
    "    lang_detected = np.argmax(np.asarray(lang_p))\n",
    "    prediction = T_matrices[lang_detected][0]\n",
    "    return lang_p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03b43962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 0 is from Language B\n",
      "Sequence 1 is from Language A\n",
      "Sequence 2 is from Language A\n",
      "Sequence 3 is from Language A\n",
      "Sequence 4 is from Language A\n",
      "Sequence 5 is from Language C\n",
      "Sequence 6 is from Language A\n",
      "Sequence 7 is from Language C\n",
      "Sequence 8 is from Language C\n",
      "Sequence 9 is from Language B\n"
     ]
    }
   ],
   "source": [
    "#Use training data to get transition matrices for each language\n",
    "T_A = T_matrix(A_tr, alphabet_dict)\n",
    "T_B = T_matrix(B_tr, alphabet_dict)\n",
    "T_C = T_matrix(C_tr, alphabet_dict)\n",
    "T_matrices = [\n",
    "    ('Language A', transition_matrix_A),\n",
    "    ('Language B', transition_matrix_B),\n",
    "    ('Language C', transition_matrix_C)\n",
    "]\n",
    "\n",
    "#Detect language for each sequence in the test set. \n",
    "predictions = pd.DataFrame()\n",
    "for i in range(len(test)):\n",
    "    log_probabilities = language_detector(test[i], T_matrices, alphabet)\n",
    "    predictions = predictions.append(\n",
    "        {\n",
    "            \"string\": f\"test_string_{i}\",\n",
    "            \"language_A\": log_probabilities[0],\n",
    "            \"language_B\": log_probabilities[1],\n",
    "            \"language_C\": log_probabilities[2]\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    #get highest log probability \n",
    "    highest_prob = np.argmax(np.asarray(log_probabilities)) \n",
    "    #get the associated langugages and display \n",
    "    predicted = T_matrices[highest_prob][0]\n",
    "    print(f\"Sequence {i} is from {predicted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b62f32",
   "metadata": {},
   "source": [
    "### 2 - Speaker identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "111f204c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique letters == ['e' 'o' 'g' 'A' 'p' 't' 'k']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Preprocessing ##\n",
    "text = ''\n",
    "with open('speaker.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "o, letters = pd.factorize(list(text)) #returns observed states and unique letters \n",
    "print('unique letters ==',letters)\n",
    "\n",
    "#transition matrix -- these are row stochastic\n",
    "#initialize the diagonal to .9 because on average a speaker says 10 phonemes\n",
    "#spread the probability mass equally elsewhere. \n",
    "A = np.array([\n",
    "    [.9,.05,.05],\n",
    "    [.05,.9,.05],\n",
    "    [.05,.05,.9]\n",
    "]) \n",
    "\n",
    "#emission matrix\n",
    "B = np.random.dirichlet((1, 1, 1), 7).transpose() #uniformly distrtibuted? \n",
    "\n",
    "#initial conditions of len 3 because there are three speakers\n",
    "#set initial conditions to equal randomly\n",
    "pi = np.array([0.32, 0.34, 0.33])\n",
    "\n",
    "pi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3def1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Parameters Alpha and Beta before EM Step##\n",
    "\n",
    "def get_alphas(A,B,os,pi):\n",
    "    '''\n",
    "    Computes alphas using forward pass.\n",
    "    \n",
    "    in:\n",
    "    A - transition matrix\n",
    "    B - emission matrix\n",
    "    os - observations\n",
    "    pi - initial condition\n",
    "    \n",
    "    out:\n",
    "    alphas -array \n",
    "    '''\n",
    "    #use formula: \\alpha_t=[\\alpha_{t-1}*A]*(b)^T(o_t)\n",
    "    \n",
    "    #initiate array to store alphas \n",
    "    #of size no. of states x observations \n",
    "    alphas = np.zeros((len(pi),len(os))) \n",
    "    \n",
    "    #initialize the first row of alpha using initial conditions\n",
    "    #so that it has the previous time step value in the loop \n",
    "    A[:,0] = pi * B[:,os[0]]\n",
    "        \n",
    "    for t in range(1,len(os)): #for each observations, comput alpha\n",
    "        alphas[:,t] = (A.T @ alphas[:,t-1]) * B[:,os[t]] \n",
    "    \n",
    "    return alphas\n",
    "\n",
    "def get_betas(A,B,os,pi):\n",
    "    ''' Computes betas using backward pass\n",
    "    in:\n",
    "    A - transition matrix\n",
    "    B - emission matrix\n",
    "    os - observations\n",
    "    pi - initial condition\n",
    "    \n",
    "    out: \n",
    "    betas - array\n",
    "    '''\n",
    "    \n",
    "    #use formula: \\beta_t-1=[A*b(o_{t+1}]*\\beta_{t+1}\n",
    "    \n",
    "    betas = np.zeros((len(pi),len(os))) \n",
    "    \n",
    "    for t in range(len(os)-1,0,-1): #count backwards!!\n",
    "        #calculate previous beta from the next time step\n",
    "        betas[:,t-1] = A @ (betas[:,t] * B[:,os[t]])\n",
    "\n",
    "    betas = np.where(betas == 0, 0.00000000001, betas)\n",
    "    \n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e0152154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baum Welch Algorithm with E-Step and M-Step function ##\n",
    "\n",
    "def E_step(A,B,os,pi):\n",
    "    '''Computes gammas and next state using alphas, betas, and initial state.\n",
    "    '''\n",
    "    \n",
    "    #get alphas and betas in E step \n",
    "    alpha = get_alphas(A,B,os,pi)\n",
    "    beta = get_betas(A,B,os,pi)\n",
    "    \n",
    "    #- We can find P(o|gamma) by marginalizing all possible hmm chains of hidden variables x as such:   \n",
    "    #$$p(o|\\gamma)=\\Sigma_{x}p(o|x,\\gamma)p(x|\\gamma)$$ by summing over alphas\n",
    "    marginal = sum(alpha[:,-1]) #p(y)\n",
    "    \n",
    "    #use formula: \\gamma_t(i)=\\frac{\\alpha_t(i)*\\beta_t(i)}{p(o|\\gamma)}\n",
    "    gamma = (alpha*beta)/marginal\n",
    "    \n",
    "    #get new pis now\n",
    "    new_pis = alpha[:,np.newaxis,0:-1] * A[:,:,np.newaxis] * B[np.newaxis,0:,os[1:]] * beta[np.newaxis,0:,1:] / marginal\n",
    "\n",
    "    return gamma, new_pis\n",
    "\n",
    "def M_step(gamma,new_pis,os):\n",
    "    '''Update transition, and emmision probabilities, and sets new initial state. \n",
    "    '''\n",
    "    letters = np.unique(os)\n",
    "    \n",
    "    #get new transition and emission matrices\n",
    "    new_A = np.sum(new_pis, axis = 2)/np.sum(new_pis, axis = (1,2))[:,np.newaxis]\n",
    "    new_B = np.zeros(B.shape)\n",
    "    \n",
    "    #get new_pi using gamma\n",
    "    pi_ = gamma[:,0]\n",
    "    \n",
    "    for j in range(0,len(letters)):\n",
    "        new_B[:,j] = np.sum(gamma[:,os == letters[j]], axis = 1) / np.sum(gamma, axis = 1)\n",
    "        \n",
    "    return new_A, new_B, pi_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e35ed585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), array([[[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]],\n",
      "\n",
      "       [[nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan],\n",
      "        [nan, nan, nan, ..., nan, nan, nan]]])]\n",
      "[[nan nan nan]\n",
      " [nan nan nan]\n",
      " [nan nan nan]]\n",
      "[[nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan]\n",
      " [nan nan nan nan nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "# Run the EM algorithm\n",
    "for steps in range(0,10):\n",
    "    [gamma, pi_i] = E_step(A, B, o, pi)\n",
    "    print([gamma, pi_i] )\n",
    "    [A,B,pi_0] = M_step(gamma, pi_i, o)\n",
    "    \n",
    "print(A)\n",
    "print(B)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
