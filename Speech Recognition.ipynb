{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d841fff0",
   "metadata": {},
   "source": [
    "## Speech recognition\n",
    "\n",
    "This week’s assignment is a simplified form of speech recognition. The languages are artificial and have been generated using a combination of Markov models and hidden Markov models (HMMs). In real life things are much more messy! This artificial data makes for a better tutorial with cleaner results. There are two forms of the datasets available. In the first form, there are several audio files, which can be parsed into discrete phonemes. In the second form, the parsing has already been done for you, and you are presented with long sequences of symbols. It is worth listening to the audio yourself, and seeing if you can determine any differences between the “languages” or “speakers” by ear! If you want to process the audio dataset, then it is advised to use: scipy.io.wavfile to read an audio file. All audio will be single channel (mono) and noiselessly generated from a small set of component sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49d3f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfec180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique letters == ['e' 'o' 'g' 'A' 'p' 't' 'k']\n"
     ]
    }
   ],
   "source": [
    "## Data Preprocessing ##\n",
    "\n",
    "text = ''\n",
    "with open('speaker.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "o, letters = pd.factorize(list(text)) #returns observed states and unique letters \n",
    "print('unique letters ==',letters)\n",
    "\n",
    "#transition matrix\n",
    "#these are row stochastic (the rows must sum to 1)\n",
    "A = np.array([\n",
    "    [.9,.05,.05],\n",
    "    [.05,.9,.05],\n",
    "    [.05,.05,.9]\n",
    "]) \n",
    "\n",
    "#emission matrix\n",
    "B = [] #uniformly distrtibuted? \n",
    "\n",
    "#initial conditions of len 3 because there are three speakers\n",
    "#set initial conditions to uniform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b13ca",
   "metadata": {},
   "source": [
    "### 1 - Language detection\n",
    "There are three languages: A, B, and C. Each language uses the same set of symbols: “A, o, e, t, p, g, and k. However, each language uses the symbols differently. In each of these languages we can model everything as P(next symbol | current symbol).\n",
    "\n",
    "There is training data available for each language. This consists of several files each generated by sampling from a Markov model. Using python, build a Markov model for each of the languages.\n",
    "Now use the Markov model and Bayes’ rule to classify the test cases. Write down how you used Bayes’ rule to get your classifier. Give the full posterior distribution for each test case.\n",
    "Audio dataset: https://course-resources.minerva.kgi.edu/uploaded_files/mke/nglEdY/audio.zip\n",
    "\n",
    "Symbol dataset: https://course-resources.minerva.kgi.edu/uploaded_files/mke/ryDvKV/symbol.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b05c1b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data set sizes\n",
      "30\n",
      "30\n",
      "30\n",
      "test data size\n",
      "10\n",
      "alphabet == ['A', 'o', 'e', 't', 'p', 'g', 'k']\n"
     ]
    }
   ],
   "source": [
    "#get file names from paths\n",
    "path = '/Users/anosharahim/cs156-pcw-anosharahim/23/'\n",
    "trainA = os.listdir(path + 'trainA')\n",
    "trainB = os.listdir(path + 'trainB')\n",
    "trainC = os.listdir(path + 'trainC')\n",
    "ts = os.listdir(path + 'test')\n",
    "\n",
    "#unique alphabet in language\n",
    "alphabet = ['A', 'o', 'e', 't', 'p', 'g', 'k']\n",
    "#create alphabet encoding\n",
    "alphabet_dict = {'o': 0, 'p': 1, 't': 2, 'e': 3, 'k': 4, 'g': 5, 'A': 6} #\n",
    "\n",
    "def getfiles(folder,folder_name, pth): \n",
    "    items = []\n",
    "    c=0\n",
    "    for item in folder: \n",
    "        myfile = open(pth+folder_name+'/'+item)\n",
    "        c+=1\n",
    "        \n",
    "        for line in myfile:\n",
    "            items.append(line)\n",
    "    print(c)   \n",
    "    return items\n",
    "\n",
    "print('training data set sizes')\n",
    "A_tr = getfiles(trainA, 'trainA', path)\n",
    "trainB.pop(18) #remove .DStore file\n",
    "B_tr = getfiles(trainB, 'trainB', path)\n",
    "C_tr = getfiles(trainC, 'trainC', path)\n",
    "print('test data size')\n",
    "test = getfiles(ts, 'test', path)\n",
    "print('alphabet ==',alphabet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "395972d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def T_matrix(sequences, dict_):\n",
    "    '''Returns transition matrix of a list of sequences. \n",
    "    \n",
    "    Input:\n",
    "    \n",
    "    sequences: list of str\n",
    "    A list of sequences as strings.\n",
    "    dict_: dict()\n",
    "    dictionary of letters as keys and their encoding as values.\n",
    "    \n",
    "    Output \n",
    "    \n",
    "    M: list of lists\n",
    "    where M[i][j] is the probability of transitioning from i to j\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #initialize transition matrix\n",
    "    M = [[0]*7 for _ in range(7)] \n",
    "    \n",
    "    for seq in sequences: #for each sequence\n",
    "        seq = list(seq) #create list from string\n",
    "        T = [dict_[letter] for letter in seq] \n",
    "        \n",
    "        for (i,j) in zip(T,T[1:]): #count them \n",
    "            M[i][j] += 1 #append count when state transitions from i to j\n",
    "            \n",
    "    #one counted, convert to probabilities\n",
    "    for row in M:\n",
    "        n = sum(row) #row should sum to 1\n",
    "        if n > 0:\n",
    "            #normalize rows\n",
    "            row[:] = [f/sum(row) for f in row]\n",
    "            \n",
    "    return M #transition matrix\n",
    "\n",
    "\n",
    "def log_probability(seq, t_matrix, letters = alphabet):\n",
    "    '''Returns log probability that a sequence is from a given language.\n",
    "    '''\n",
    "    log_prob = 0 #initialize log probability \n",
    "    \n",
    "    for i in range(len(seq)-1): #for each sequence\n",
    "        \n",
    "        #get current and next letter\n",
    "        curr_ = letters.index(seq[i])\n",
    "        next_ = letters.index(seq[i+1])\n",
    "        #find probability of going from curr to next\n",
    "        #in the transition matrix\n",
    "        prob = t_matrix[curr_, next_]\n",
    "        \n",
    "        #check if probability is greater than 0\n",
    "        if prob > 0:\n",
    "            log_prob += np.log(prob)\n",
    "        \n",
    "    return log_prob \n",
    "\n",
    "\n",
    "def language_detector(seq, t_matrices, letters = alphabet):\n",
    "    lang_p = []\n",
    "    for name, t_matrix in t_matrices:\n",
    "        lang_p.append(log_probability(seq, t_matrix, letters))\n",
    "    return lang_p    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4752d697",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9q/1_qpd4b14hb9pgg5pyh9fz2h0000gn/T/ipykernel_961/3541474327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransition_matrices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     results = results.append(\n\u001b[1;32m     17\u001b[0m         {\n",
      "\u001b[0;32m/var/folders/9q/1_qpd4b14hb9pgg5pyh9fz2h0000gn/T/ipykernel_961/2683713866.py\u001b[0m in \u001b[0;36mlanguage_detector\u001b[0;34m(seq, t_matrices, letters)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mlang_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_matrix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt_matrices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mlang_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlang_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/9q/1_qpd4b14hb9pgg5pyh9fz2h0000gn/T/ipykernel_961/2683713866.py\u001b[0m in \u001b[0;36mlog_probability\u001b[0;34m(seq, t_matrix, letters)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m#find probability of going from curr to next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#in the transition matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurr_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m#check if probability is greater than 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "transition_matrix_A = T_matrix(A_tr, alphabet_dict)\n",
    "transition_matrix_B = T_matrix(B_tr, alphabet_dict)\n",
    "transition_matrix_C = T_matrix(C_tr, alphabet_dict)\n",
    "\n",
    "transition_matrices = [\n",
    "    ('Language A', transition_matrix_A),\n",
    "    ('Language B', transition_matrix_B),\n",
    "    ('Language C', transition_matrix_C)\n",
    "]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    log_probs = language_detector(test[i], transition_matrices, alphabet)\n",
    "    results = results.append(\n",
    "        {\n",
    "            \"string\": f\"test_string_{i}\",\n",
    "            \"language_A\": log_probs[0],\n",
    "            \"language_B\": log_probs[1],\n",
    "            \"language_C\": log_probs[2]\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "    most_probable = np.argmax(np.asarray(log_probs))\n",
    "    pred_language = transition_matrices[most_probable][0]\n",
    "    print(f\"For the string {i}, prediction is: {pred_language}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b62f32",
   "metadata": {},
   "source": [
    "### 2 - Speaker identification\n",
    "There are three people in a room. Each says about 10 phonemes, before being randomly interrupted by someone else. When they speak they all sound the same, however each person tends to use different phonemes in their speech. Specifically we can model the following transition probabilities that someone will interrupt the current speaker: P(speaker i at time t+1 | speaker j at time t). We can also model the probability over phonemes given a particular speaker: P(phoneme | speaker i). The phonemes are identical to the ones introduced in problem 1 (but the transition matrices are obviously different, since they take a different form altogether).\n",
    "\n",
    "Write down the update equations that you will need to train a hidden Markov model. Using the information given above, write down a sensible initialization for the transition matrix.\n",
    "Write your own python code to train a hidden Markov model on the data. You may look at code online, but will need to reference any code that helps you with your implementation.\n",
    "From matplotlb use a stackplot (https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.stackplot.html) to show the probability of a particular person speaking.\n",
    "Audio dataset: https://course-resources.minerva.kgi.edu/uploaded_files/mke/VW8Rjr/speaker.wav.zip Symbol dataset: https://course-resources.minerva.kgi.edu/uploaded_files/mke/n705lY/speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3def1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate Parameters Alpha and Beta ##\n",
    "\n",
    "def get_alphas(A,B,os,pi):\n",
    "    '''\n",
    "    in:\n",
    "    A - transition matrix\n",
    "    B - emission matrix\n",
    "    os - observations\n",
    "    pi - initial condition\n",
    "    \n",
    "    out:\n",
    "    alphas\n",
    "    '''\n",
    "    #use formula: \\alpha_t=[\\alpha_{t-1}*A]*(b)^T(o_t)\n",
    "    \n",
    "    #initiate array to store alphas \n",
    "    #of size no. of states x observations \n",
    "    alphas = np.zeros((len(pi),len(os))) \n",
    "    \n",
    "    #initialize the first row of alpha using initial conditions\n",
    "    #so that it has the previous time step value in the loop \n",
    "    A[:,0] = pi * B[:,0]\n",
    "        \n",
    "    for t in range(1,len(os)): #for each observations, comput alpha\n",
    "        alphas[:,t] = (A.T @ alphas[:,t-1]) * B[:,os[t]] \n",
    "    \n",
    "    return alphas\n",
    "\n",
    "def get_betas(A,B,os,pi):\n",
    "    #use formula: \\beta_t-1=[A*b(o_{t+1}]*\\beta_{t+1}\n",
    "    \n",
    "    betas = np.zeros((len(pi),len(os))) \n",
    "    \n",
    "    for t in range(1,len(os)): #count backwards!!\n",
    "        #calculate previous beta from the next time step\n",
    "        betas[:,t] = (A @ B[:,os[t+1]]) * betas[:,t+1]\n",
    "    \n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0152154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baum Welch Algorithm ##\n",
    "\n",
    "def E_step(A,B,os,pi):\n",
    "    #use alphas and betas in E step \n",
    "    alpha = get_alphas(A,B,os,pi)\n",
    "    beta = get_betas(A,B,os,pi)\n",
    "    \n",
    "    #- We can find P(o|gamma) by marginalizing all possible hmm chains of hidden variables x as such:   \n",
    "    #$$p(o|\\gamma)=\\Sigma_{x}p(o|x,\\gamma)p(x|\\gamma)$$\n",
    "    marginal = #sum of all somethings\n",
    "    \n",
    "    #use formula: \\gamma_t(i)=\\frac{\\alpha_t(i)*\\beta_t(i)}{p(o|\\gamma)}\n",
    "    gamma = (alpha*beta)/marginal\n",
    "    \n",
    "    #get new pis now\n",
    "    #pis = do something\n",
    "    return gamma, new_pis\n",
    "\n",
    "def M_step(gamma,new_pis):\n",
    "    \n",
    "    #get new transition and emission matrix\n",
    "    #get new_pi using gamma\n",
    "    \n",
    "    return\n",
    "\n",
    "#run the E-M algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
